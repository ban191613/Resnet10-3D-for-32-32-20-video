{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21564, 3, 32, 32]) torch.Size([21564])\n",
      "torch.Size([3008, 3, 32, 32]) torch.Size([3008])\n",
      "Finished reading the train set of Leaves Dataset (21564 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (0 samples found)\n",
      "Finished reading the test set of Leaves Dataset (3008 samples found)\n",
      "cpu\n",
      "<bound method Module.parameters of ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.167)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2dSame(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.333)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2dSame(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
      "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.500)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=2, bias=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:46<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个epoch的学习率：0.000099\n",
      "[ Train | 001/050 ] loss = 0.33360, acc = 0.88479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.38181, acc = 0.83544\n",
      "saving model with acc 0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:49<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个epoch的学习率：0.000099\n",
      "[ Train | 002/050 ] loss = 0.22957, acc = 0.92776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.49712, acc = 0.81350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:45<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3个epoch的学习率：0.000100\n",
      "[ Train | 003/050 ] loss = 0.20792, acc = 0.93300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.47822, acc = 0.82480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:45<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第4个epoch的学习率：0.000100\n",
      "[ Train | 004/050 ] loss = 0.20020, acc = 0.93240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.47412, acc = 0.81549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:44<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5个epoch的学习率：0.000100\n",
      "[ Train | 005/050 ] loss = 0.19649, acc = 0.93537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.37103, acc = 0.84475\n",
      "saving model with acc 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:45<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第6个epoch的学习率：0.000100\n",
      "[ Train | 006/050 ] loss = 0.19388, acc = 0.93523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.69900, acc = 0.81051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:46<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第7个epoch的学习率：0.000100\n",
      "[ Train | 007/050 ] loss = 0.19244, acc = 0.93523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.51568, acc = 0.83777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:47<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第8个epoch的学习率：0.000100\n",
      "[ Train | 008/050 ] loss = 0.18953, acc = 0.93750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.66627, acc = 0.81549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:41<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第9个epoch的学习率：0.000100\n",
      "[ Train | 009/050 ] loss = 0.18704, acc = 0.93769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.63833, acc = 0.82812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:48<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第10个epoch的学习率：0.000100\n",
      "[ Train | 010/050 ] loss = 0.18606, acc = 0.93857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 62.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.75261, acc = 0.81815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:46<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第11个epoch的学习率：0.000100\n",
      "[ Train | 011/050 ] loss = 0.18353, acc = 0.94149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 61.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.78559, acc = 0.82580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:45<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第12个epoch的学习率：0.000100\n",
      "[ Train | 012/050 ] loss = 0.18236, acc = 0.94103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.93678, acc = 0.83178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:43<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第13个epoch的学习率：0.000100\n",
      "[ Train | 013/050 ] loss = 0.18621, acc = 0.93704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.44789, acc = 0.82646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:44<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第14个epoch的学习率：0.000100\n",
      "[ Train | 014/050 ] loss = 0.18538, acc = 0.93875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.13142, acc = 0.81782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:48<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第15个epoch的学习率：0.000100\n",
      "[ Train | 015/050 ] loss = 0.18311, acc = 0.93950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 60.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.58790, acc = 0.83544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:56<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第16个epoch的学习率：0.000100\n",
      "[ Train | 016/050 ] loss = 0.18632, acc = 0.94260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.64278, acc = 0.82048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:53<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第17个epoch的学习率：0.000100\n",
      "[ Train | 017/050 ] loss = 0.17940, acc = 0.94028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 62.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.78345, acc = 0.77693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:52<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第18个epoch的学习率：0.000100\n",
      "[ Train | 018/050 ] loss = 0.18259, acc = 0.94163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.67228, acc = 0.74235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第19个epoch的学习率：0.000100\n",
      "[ Train | 019/050 ] loss = 0.17921, acc = 0.93769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 54.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.83052, acc = 0.72374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [03:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第20个epoch的学习率：0.000100\n",
      "[ Train | 020/050 ] loss = 0.18176, acc = 0.94172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 61.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.88870, acc = 0.85239\n",
      "saving model with acc 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第21个epoch的学习率：0.000100\n",
      "[ Train | 021/050 ] loss = 0.17810, acc = 0.94084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 61.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.11971, acc = 0.81948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:55<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第22个epoch的学习率：0.000100\n",
      "[ Train | 022/050 ] loss = 0.18086, acc = 0.94079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.19062, acc = 0.82746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第23个epoch的学习率：0.000100\n",
      "[ Train | 023/050 ] loss = 0.18028, acc = 0.94079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 60.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.60097, acc = 0.82846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:55<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第24个epoch的学习率：0.000100\n",
      "[ Train | 024/050 ] loss = 0.17790, acc = 0.94437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 62.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.68839, acc = 0.84608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:51<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第25个epoch的学习率：0.000100\n",
      "[ Train | 025/050 ] loss = 0.17954, acc = 0.94005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 62.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.65830, acc = 0.85040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第26个epoch的学习率：0.000100\n",
      "[ Train | 026/050 ] loss = 0.17655, acc = 0.94316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.61718, acc = 0.83477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第27个epoch的学习率：0.000100\n",
      "[ Train | 027/050 ] loss = 0.18010, acc = 0.94195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 61.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.82800, acc = 0.85140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第28个epoch的学习率：0.000100\n",
      "[ Train | 028/050 ] loss = 0.18111, acc = 0.94070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.25901, acc = 0.84408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第29个epoch的学习率：0.000100\n",
      "[ Train | 029/050 ] loss = 0.18183, acc = 0.94186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.82783, acc = 0.84874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:58<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第30个epoch的学习率：0.000100\n",
      "[ Train | 030/050 ] loss = 0.17701, acc = 0.94130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.28407, acc = 0.82779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:55<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第31个epoch的学习率：0.000100\n",
      "[ Train | 031/050 ] loss = 0.17712, acc = 0.94358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 62.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.14362, acc = 0.84009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第32个epoch的学习率：0.000100\n",
      "[ Train | 032/050 ] loss = 0.17896, acc = 0.94423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.03126, acc = 0.84874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [03:00<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第33个epoch的学习率：0.000100\n",
      "[ Train | 033/050 ] loss = 0.17477, acc = 0.94455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 61.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.45614, acc = 0.84940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:56<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第34个epoch的学习率：0.000100\n",
      "[ Train | 034/050 ] loss = 0.17746, acc = 0.94228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.32502, acc = 0.85572\n",
      "saving model with acc 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第35个epoch的学习率：0.000100\n",
      "[ Train | 035/050 ] loss = 0.17683, acc = 0.94390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.89937, acc = 0.85771\n",
      "saving model with acc 0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [03:01<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第36个epoch的学习率：0.000100\n",
      "[ Train | 036/050 ] loss = 0.18229, acc = 0.94200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.46886, acc = 0.85904\n",
      "saving model with acc 0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:49<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第37个epoch的学习率：0.000100\n",
      "[ Train | 037/050 ] loss = 0.18176, acc = 0.94265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.84143, acc = 0.85339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:59<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第38个epoch的学习率：0.000100\n",
      "[ Train | 038/050 ] loss = 0.17523, acc = 0.94209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:03<00:00, 60.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.52258, acc = 0.85306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [03:04<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第39个epoch的学习率：0.000100\n",
      "[ Train | 039/050 ] loss = 0.17714, acc = 0.94228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.18638, acc = 0.84840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [03:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第40个epoch的学习率：0.000100\n",
      "[ Train | 040/050 ] loss = 0.17347, acc = 0.94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.20787, acc = 0.85372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:49<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第41个epoch的学习率：0.000100\n",
      "[ Train | 041/050 ] loss = 0.17565, acc = 0.94414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.50744, acc = 0.85439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:51<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第42个epoch的学习率：0.000100\n",
      "[ Train | 042/050 ] loss = 0.18059, acc = 0.94121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.61549, acc = 0.84176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第43个epoch的学习率：0.000100\n",
      "[ Train | 043/050 ] loss = 0.17360, acc = 0.94339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.10418, acc = 0.85206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:51<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第44个epoch的学习率：0.000100\n",
      "[ Train | 044/050 ] loss = 0.17870, acc = 0.94182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.60798, acc = 0.82713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:52<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第45个epoch的学习率：0.000100\n",
      "[ Train | 045/050 ] loss = 0.17598, acc = 0.94386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.55696, acc = 0.82680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:52<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第46个epoch的学习率：0.000100\n",
      "[ Train | 046/050 ] loss = 0.17821, acc = 0.94158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 65.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.12000, acc = 0.83012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:53<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第47个epoch的学习率：0.000100\n",
      "[ Train | 047/050 ] loss = 0.17526, acc = 0.94274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.30561, acc = 0.82945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:54<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第48个epoch的学习率：0.000100\n",
      "[ Train | 048/050 ] loss = 0.17867, acc = 0.94302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.43644, acc = 0.83910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第49个epoch的学习率：0.000100\n",
      "[ Train | 049/050 ] loss = 0.17596, acc = 0.94117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.06628, acc = 0.85439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [02:57<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第50个epoch的学习率：0.000100\n",
      "[ Train | 050/050 ] loss = 0.17969, acc = 0.94219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:02<00:00, 64.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.08677, acc = 0.84641\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm  # timm库有更丰富的预训练模型\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# 设置文件路径并得到数据集\n",
    "train_data_file = \"../CNN/data/train_data/\"\n",
    "test_data_file = \"../CNN/data/test_data/\"\n",
    "# model_path   torch.save(model.state_dict(), '../CNN/Cmodel_weights.pth')\n",
    "model_path = \"../CNN/\"\n",
    "\n",
    "# 超参数\n",
    "learning_rate = 1e-6  # 1e-4\n",
    "weight_decay = 1e-3\n",
    "batch_size = 16\n",
    "n_epochs = 50\n",
    "best_acc= 0\n",
    "#提取数据\n",
    "def data_image_label(mode):  #shuffle\n",
    "        if mode == 'train':\n",
    "            for i in range(1, 9):\n",
    "                date_path = f\"{train_data_file}\" + \"traindata\" + f\"{i}\" + \".mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            #shuffle\n",
    "            index = [i for i in range(len(data_image))]\n",
    "            random.shuffle(index)\n",
    "            random.shuffle(index)\n",
    "            data_image = data_image[index,:,:,:]\n",
    "            data_label = data_label[index,:]\n",
    "\n",
    "\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            #  #valid_date\n",
    "            # valid_image_tensor=image_tensor[:self.valid_len,:,:,:]\n",
    "            # valid_label_tensor=label_tensor[:self.valid_len]\n",
    "            # #train_date\n",
    "            # image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            # label_tensor=self.label_tensor[self.valid_len:]\n",
    "            # real_len=len(self.image_tensor)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "        elif mode == \"test\":\n",
    "            for i in range(1, 5):\n",
    "                date_path = f\"{test_data_file}\" + \"testdata\" + f\"{i}\" + \"_label.mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "train_image_tensor,train_label_tensor,train_real_len=data_image_label('train')\n",
    "test_image_tensor,test_label_tensor,test_real_len=data_image_label('test')\n",
    "\n",
    "class SAPI_FMF_Dataset(Dataset):\n",
    "    def __init__(self,image_data,label_data,data_len,mode=\"train\", valid_ratio=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (string): 图像文件 路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        self.image_tensor=image_data\n",
    "        self.label_tensor=label_data\n",
    "        self.real_len=data_len\n",
    "        self.mode = mode\n",
    "        self.valid_ratio = valid_ratio\n",
    "        self.valid_len=int(self.valid_ratio*self.real_len)\n",
    "        if self.mode == 'train':\n",
    "            self.image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            self.label_tensor=self.label_tensor[self.valid_len:]\n",
    "            self.real_len=len(self.image_tensor)\n",
    "        elif self.mode == 'valid':\n",
    "            self.valid_image_tensor=self.image_tensor[:self.valid_len,:,:,:]\n",
    "            self.valid_label_tensor=self.label_tensor[:self.valid_len]\n",
    "            self.real_len=len(self.valid_image_tensor)\n",
    "        elif self.mode == 'test':\n",
    "            pass\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.real_len))\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        return self.image_tensor[index, :, :, :], self.label_tensor[index]\n",
    "    def __len__(self):\n",
    "        return self.real_len  # self.real_len = len(self.image_arr) 返回的是训练/验证/测试/图像的数量\n",
    "train_dataset = SAPI_FMF_Dataset(train_image_tensor,train_label_tensor,train_real_len,mode='train')\n",
    "valid_dataset = SAPI_FMF_Dataset( train_image_tensor,train_label_tensor,train_real_len,mode='valid')\n",
    "test_dataset = SAPI_FMF_Dataset( test_image_tensor,test_label_tensor,test_real_len,mode='test')\n",
    "\n",
    "\n",
    "# 定义data loader\n",
    "train_Dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)  # 打开乱序  Falsenum_workers=0)\n",
    "valid_Dataloader = torch.utils.data.DataLoader(dataset=valid_dataset,batch_size=batch_size,shuffle=False,drop_last=True)   #打开乱序  Falsenum_workers=0)\n",
    "test_Dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,drop_last=False)\n",
    "# GPU计算\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "model = timm.create_model(\"resnet10t\",num_classes=2,in_chans=3,pretrained=True,output_stride=8,drop_rate=.5,drop_path_rate=0.5,drop_block_rate=0)\n",
    "# model = timm.create_model(\"resnet18\")\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(.5),\n",
    "    nn.Linear(model.fc.in_features, 2),\n",
    "    nn.Dropout(.5)\n",
    ")\n",
    "model.to(device)\n",
    "model.device = device\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4,\n",
    "                        weight_decay=weight_decay)  # lr=learning_rate,weight_decay= weight_decay\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "print(model.parameters)\n",
    "# train\n",
    "# 对于分类任务，我们使用交叉熵作为性能的度量。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 记录训练信息\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for batch in tqdm(train_Dataloader):\n",
    "        # ---------- Training ----------  以下是训练模型\n",
    "        imgs, labels = batch\n",
    "        # print(imgs.shape)\n",
    "\n",
    "        logits = model(imgs)  # 将图形数据带入模型计算预测\n",
    "        # 计算交叉熵损失\n",
    "        loss = criterion(logits, labels)\n",
    "        # 清除上一步中存储在参数中的梯度。\n",
    "        optimizer.zero_grad()\n",
    "        # 计算参数的梯度。\n",
    "        loss.backward()\n",
    "        # 用计算的梯度更新参数。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算当前批次的精度。   第一维度是0，第二维度是1\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        # 记录损失和准确度\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # 训练集的平均损失和精度是记录值的平均值。\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    # 更新学习率\n",
    "    scheduler.step(train_loss)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch + 1, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    # 打印信息\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "# ---------- test ----------\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_accs = []\n",
    "    for batch in tqdm(test_Dataloader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # 不需要梯度验证.\n",
    "        # Using  torch.no_grad()  accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # 我们仍然可以计算损失（但不能计算梯度）。\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # 计算当前批次的精度。\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # 记录损失和准确性\n",
    "        test_loss.append(loss.item())\n",
    "        test_accs.append(acc)\n",
    "\n",
    "    # 整个验证集的平均损失和准确度是记录值的平均值\n",
    "    test_loss = sum(test_loss) / len(test_loss)\n",
    "    test_accs = sum(test_accs) / len(test_accs)\n",
    "\n",
    "    # 打印信息.\n",
    "    print(f\"[ test ]  loss = {test_loss:.5f}, acc = {test_accs:.5f}\")\n",
    "  # 如果模型改进了，在这个时间点保存一个检查点\n",
    "    if test_accs > best_acc:\n",
    "        best_acc = test_accs\n",
    "        net_name=\"_resnet10_\"\n",
    "        path=model_path+\"model_weights_2d_\"+f\"{net_name}\"+f'{best_acc}'+\".pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('saving model with acc {:.3f}'.format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21564, 3, 32, 32]) torch.Size([21564])\n",
      "torch.Size([3008, 3, 32, 32]) torch.Size([3008])\n",
      "Finished reading the train set of Leaves Dataset (21564 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (0 samples found)\n",
      "Finished reading the test set of Leaves Dataset (3008 samples found)\n",
      "cpu\n",
      "<bound method Module.parameters of ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (drop_path): DropPath(drop_prob=0.071)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.143)\n",
      "    )\n",
      "    (1): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (drop_path): DropPath(drop_prob=0.214)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.286)\n",
      "    )\n",
      "    (1): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (drop_path): DropPath(drop_prob=0.357)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (drop_path): DropPath(drop_prob=0.429)\n",
      "    )\n",
      "    (1): SelectiveKernelBasic(\n",
      "      (conv1): SelectiveKernel(\n",
      "        (paths): ModuleList(\n",
      "          (0): ConvNormActAa(\n",
      "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "          (1): ConvNormActAa(\n",
      "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
      "            (bn): BatchNormAct2d(\n",
      "              512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (aa): Identity()\n",
      "          )\n",
      "        )\n",
      "        (attn): SelectiveKernelAttn(\n",
      "          (fc_reduce): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "          (fc_select): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv2): ConvNormAct(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn): BatchNormAct2d(\n",
      "          512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "      )\n",
      "      (act): ReLU(inplace=True)\n",
      "      (drop_path): DropPath(drop_prob=0.500)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=2, bias=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:41<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个epoch的学习率：0.000099\n",
      "[ Train | 001/050 ] loss = 0.36953, acc = 0.87036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.81996, acc = 0.83078\n",
      "saving model with acc 0.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:15<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个epoch的学习率：0.000099\n",
      "[ Train | 002/050 ] loss = 0.25216, acc = 0.91922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.14010, acc = 0.58245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:16<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3个epoch的学习率：0.000100\n",
      "[ Train | 003/050 ] loss = 0.22049, acc = 0.92868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.10988, acc = 0.76230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:16<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第4个epoch的学习率：0.000100\n",
      "[ Train | 004/050 ] loss = 0.21221, acc = 0.92827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.09781, acc = 0.54654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:22<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5个epoch的学习率：0.000100\n",
      "[ Train | 005/050 ] loss = 0.21435, acc = 0.92878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.50846, acc = 0.54820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:33<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第6个epoch的学习率：0.000100\n",
      "[ Train | 006/050 ] loss = 0.20703, acc = 0.93295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.25099, acc = 0.71941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:27<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第7个epoch的学习率：0.000100\n",
      "[ Train | 007/050 ] loss = 0.19787, acc = 0.93318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.27889, acc = 0.79787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:26<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第8个epoch的学习率：0.000100\n",
      "[ Train | 008/050 ] loss = 0.20646, acc = 0.93383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.10080, acc = 0.77926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:40<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第9个epoch的学习率：0.000100\n",
      "[ Train | 009/050 ] loss = 0.20341, acc = 0.93346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.89053, acc = 0.77626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第10个epoch的学习率：0.000100\n",
      "[ Train | 010/050 ] loss = 0.19919, acc = 0.93550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.91487, acc = 0.74269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:35<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第11个epoch的学习率：0.000100\n",
      "[ Train | 011/050 ] loss = 0.19564, acc = 0.93486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.48380, acc = 0.71343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:41<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第12个epoch的学习率：0.000100\n",
      "[ Train | 012/050 ] loss = 0.19757, acc = 0.93509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.24587, acc = 0.75432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:32<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第13个epoch的学习率：0.000100\n",
      "[ Train | 013/050 ] loss = 0.19654, acc = 0.93486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.59531, acc = 0.48936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:16<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第14个epoch的学习率：0.000100\n",
      "[ Train | 014/050 ] loss = 0.19355, acc = 0.93411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.26962, acc = 0.63065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:19<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第15个epoch的学习率：0.000100\n",
      "[ Train | 015/050 ] loss = 0.19210, acc = 0.93588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.69654, acc = 0.66888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第16个epoch的学习率：0.000100\n",
      "[ Train | 016/050 ] loss = 0.19295, acc = 0.93555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.55983, acc = 0.55419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:34<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第17个epoch的学习率：0.000100\n",
      "[ Train | 017/050 ] loss = 0.19161, acc = 0.93680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.20904, acc = 0.80652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:47<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第18个epoch的学习率：0.000100\n",
      "[ Train | 018/050 ] loss = 0.19425, acc = 0.93407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.28167, acc = 0.65858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:40<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第19个epoch的学习率：0.000100\n",
      "[ Train | 019/050 ] loss = 0.18619, acc = 0.93694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.17393, acc = 0.81981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:33<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第20个epoch的学习率：0.000100\n",
      "[ Train | 020/050 ] loss = 0.19520, acc = 0.93481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.02531, acc = 0.81616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:43<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第21个epoch的学习率：0.000100\n",
      "[ Train | 021/050 ] loss = 0.18819, acc = 0.93857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.95503, acc = 0.68484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [07:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第22个epoch的学习率：0.000100\n",
      "[ Train | 022/050 ] loss = 0.18477, acc = 0.93982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.83860, acc = 0.61303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:51<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第23个epoch的学习率：0.000100\n",
      "[ Train | 023/050 ] loss = 0.18549, acc = 0.93782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.72375, acc = 0.48138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:48<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第24个epoch的学习率：0.000100\n",
      "[ Train | 024/050 ] loss = 0.18661, acc = 0.93834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.89548, acc = 0.67686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:38<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第25个epoch的学习率：0.000100\n",
      "[ Train | 025/050 ] loss = 0.18847, acc = 0.93806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.05327, acc = 0.73903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第26个epoch的学习率：0.000100\n",
      "[ Train | 026/050 ] loss = 0.18881, acc = 0.93801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.36927, acc = 0.73205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:29<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第27个epoch的学习率：0.000100\n",
      "[ Train | 027/050 ] loss = 0.18749, acc = 0.93755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.22937, acc = 0.79089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第28个epoch的学习率：0.000100\n",
      "[ Train | 028/050 ] loss = 0.18587, acc = 0.93922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.35754, acc = 0.74435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第29个epoch的学习率：0.000100\n",
      "[ Train | 029/050 ] loss = 0.18454, acc = 0.93741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.45056, acc = 0.66024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:34<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第30个epoch的学习率：0.000100\n",
      "[ Train | 030/050 ] loss = 0.18782, acc = 0.93759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.08068, acc = 0.79820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:35<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第31个epoch的学习率：0.000100\n",
      "[ Train | 031/050 ] loss = 0.18576, acc = 0.93639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.26018, acc = 0.69016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第32个epoch的学习率：0.000100\n",
      "[ Train | 032/050 ] loss = 0.18495, acc = 0.93871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.82942, acc = 0.57015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第33个epoch的学习率：0.000100\n",
      "[ Train | 033/050 ] loss = 0.18427, acc = 0.93810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.78419, acc = 0.70279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第34个epoch的学习率：0.000100\n",
      "[ Train | 034/050 ] loss = 0.18540, acc = 0.94047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.54548, acc = 0.72207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第35个epoch的学习率：0.000100\n",
      "[ Train | 035/050 ] loss = 0.18608, acc = 0.94019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.74209, acc = 0.76862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第36个epoch的学习率：0.000100\n",
      "[ Train | 036/050 ] loss = 0.18054, acc = 0.93977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.48096, acc = 0.72074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:32<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第37个epoch的学习率：0.000100\n",
      "[ Train | 037/050 ] loss = 0.18416, acc = 0.94140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.36586, acc = 0.76297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第38个epoch的学习率：0.000100\n",
      "[ Train | 038/050 ] loss = 0.18251, acc = 0.93959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.43473, acc = 0.70180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:34<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第39个epoch的学习率：0.000100\n",
      "[ Train | 039/050 ] loss = 0.18549, acc = 0.93926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.15077, acc = 0.47307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:35<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第40个epoch的学习率：0.000100\n",
      "[ Train | 040/050 ] loss = 0.18209, acc = 0.94042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.48389, acc = 0.68185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:36<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第41个epoch的学习率：0.000100\n",
      "[ Train | 041/050 ] loss = 0.18140, acc = 0.93908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.65815, acc = 0.65725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:36<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第42个epoch的学习率：0.000100\n",
      "[ Train | 042/050 ] loss = 0.18161, acc = 0.94214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.89431, acc = 0.78191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:33<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第43个epoch的学习率：0.000100\n",
      "[ Train | 043/050 ] loss = 0.18713, acc = 0.94209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.65913, acc = 0.64694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第44个epoch的学习率：0.000100\n",
      "[ Train | 044/050 ] loss = 0.18165, acc = 0.94056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.05913, acc = 0.69049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:32<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第45个epoch的学习率：0.000100\n",
      "[ Train | 045/050 ] loss = 0.18228, acc = 0.93880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.94587, acc = 0.72806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:30<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第46个epoch的学习率：0.000100\n",
      "[ Train | 046/050 ] loss = 0.18690, acc = 0.93996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.47790, acc = 0.61935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第47个epoch的学习率：0.000100\n",
      "[ Train | 047/050 ] loss = 0.18000, acc = 0.94302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.94946, acc = 0.66456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:32<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第48个epoch的学习率：0.000100\n",
      "[ Train | 048/050 ] loss = 0.17952, acc = 0.93991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.43852, acc = 0.78324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:33<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第49个epoch的学习率：0.000100\n",
      "[ Train | 049/050 ] loss = 0.18093, acc = 0.94270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.82385, acc = 0.69781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [06:31<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第50个epoch的学习率：0.000100\n",
      "[ Train | 050/050 ] loss = 0.18259, acc = 0.93898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:06<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.28513, acc = 0.69581\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm  # timm库有更丰富的预训练模型\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# 设置文件路径并得到数据集\n",
    "train_data_file = \"../CNN/data/train_data/\"\n",
    "test_data_file = \"../CNN/data/test_data/\"\n",
    "# model_path   torch.save(model.state_dict(), '../CNN/Cmodel_weights.pth')\n",
    "model_path = \"../CNN/\"\n",
    "\n",
    "# 超参数\n",
    "learning_rate = 1e-3  # 1e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 16\n",
    "n_epochs = 50\n",
    "best_acc= 0\n",
    "#提取数据\n",
    "def data_image_label(mode):  #shuffle\n",
    "        if mode == 'train':\n",
    "            for i in range(1, 9):\n",
    "                date_path = f\"{train_data_file}\" + \"traindata\" + f\"{i}\" + \".mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            #shuffle\n",
    "            index = [i for i in range(len(data_image))]\n",
    "            random.shuffle(index)\n",
    "            random.shuffle(index)\n",
    "            data_image = data_image[index,:,:,:]\n",
    "            data_label = data_label[index,:]\n",
    "\n",
    "\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            #  #valid_date\n",
    "            # valid_image_tensor=image_tensor[:self.valid_len,:,:,:]\n",
    "            # valid_label_tensor=label_tensor[:self.valid_len]\n",
    "            # #train_date\n",
    "            # image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            # label_tensor=self.label_tensor[self.valid_len:]\n",
    "            # real_len=len(self.image_tensor)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "        elif mode == \"test\":\n",
    "            for i in range(1, 5):\n",
    "                date_path = f\"{test_data_file}\" + \"testdata\" + f\"{i}\" + \"_label.mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "train_image_tensor,train_label_tensor,train_real_len=data_image_label('train')\n",
    "test_image_tensor,test_label_tensor,test_real_len=data_image_label('test')\n",
    "\n",
    "class SAPI_FMF_Dataset(Dataset):\n",
    "    def __init__(self,image_data,label_data,data_len,mode=\"train\", valid_ratio=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (string): 图像文件 路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        self.image_tensor=image_data\n",
    "        self.label_tensor=label_data\n",
    "        self.real_len=data_len\n",
    "        self.mode = mode\n",
    "        self.valid_ratio = valid_ratio\n",
    "        self.valid_len=int(self.valid_ratio*self.real_len)\n",
    "        if self.mode == 'train':\n",
    "            self.image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            self.label_tensor=self.label_tensor[self.valid_len:]\n",
    "            self.real_len=len(self.image_tensor)\n",
    "        elif self.mode == 'valid':\n",
    "            self.valid_image_tensor=self.image_tensor[:self.valid_len,:,:,:]\n",
    "            self.valid_label_tensor=self.label_tensor[:self.valid_len]\n",
    "            self.real_len=len(self.valid_image_tensor)\n",
    "        elif self.mode == 'test':\n",
    "            pass\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.real_len))\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        return self.image_tensor[index, :, :, :], self.label_tensor[index]\n",
    "    def __len__(self):\n",
    "        return self.real_len  # self.real_len = len(self.image_arr) 返回的是训练/验证/测试/图像的数量\n",
    "train_dataset = SAPI_FMF_Dataset(train_image_tensor,train_label_tensor,train_real_len,mode='train')\n",
    "valid_dataset = SAPI_FMF_Dataset( train_image_tensor,train_label_tensor,train_real_len,mode='valid')\n",
    "test_dataset = SAPI_FMF_Dataset( test_image_tensor,test_label_tensor,test_real_len,mode='test')\n",
    "\n",
    "\n",
    "# 定义data loader\n",
    "train_Dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)  # 打开乱序  Falsenum_workers=0)\n",
    "valid_Dataloader = torch.utils.data.DataLoader(dataset=valid_dataset,batch_size=batch_size,shuffle=False,drop_last=True)   #打开乱序  Falsenum_workers=0)\n",
    "test_Dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,drop_last=False)\n",
    "# GPU计算\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "model = timm.create_model(\"skresnet18\",num_classes=2,in_chans=3,pretrained=True,output_stride=8,drop_rate=.5,drop_path_rate=0.5)\n",
    "# model = timm.create_model(\"resnet18\")\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(.5),\n",
    "    nn.Linear(model.fc.in_features, 2),\n",
    "    nn.Dropout(.5)\n",
    ")\n",
    "model.to(device)\n",
    "model.device = device\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4,\n",
    "                        weight_decay=weight_decay)  # lr=learning_rate,weight_decay= weight_decay\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "print(model.parameters)\n",
    "# train\n",
    "# 对于分类任务，我们使用交叉熵作为性能的度量。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 记录训练信息\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for batch in tqdm(train_Dataloader):\n",
    "        # ---------- Training ----------  以下是训练模型\n",
    "        imgs, labels = batch\n",
    "        # print(imgs.shape)\n",
    "\n",
    "        logits = model(imgs)  # 将图形数据带入模型计算预测\n",
    "        # 计算交叉熵损失\n",
    "        loss = criterion(logits, labels)\n",
    "        # 清除上一步中存储在参数中的梯度。\n",
    "        optimizer.zero_grad()\n",
    "        # 计算参数的梯度。\n",
    "        loss.backward()\n",
    "        # 用计算的梯度更新参数。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算当前批次的精度。   第一维度是0，第二维度是1\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        # 记录损失和准确度\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # 训练集的平均损失和精度是记录值的平均值。\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    # 更新学习率\n",
    "    scheduler.step(train_loss)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch + 1, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    # 打印信息\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "# ---------- test ----------\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_accs = []\n",
    "    for batch in tqdm(test_Dataloader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # 不需要梯度验证.\n",
    "        # Using  torch.no_grad()  accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # 我们仍然可以计算损失（但不能计算梯度）。\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # 计算当前批次的精度。\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # 记录损失和准确性\n",
    "        test_loss.append(loss.item())\n",
    "        test_accs.append(acc)\n",
    "\n",
    "    # 整个验证集的平均损失和准确度是记录值的平均值\n",
    "    test_loss = sum(test_loss) / len(test_loss)\n",
    "    test_accs = sum(test_accs) / len(test_accs)\n",
    "\n",
    "    # 打印信息.\n",
    "    print(f\"[ test ]  loss = {test_loss:.5f}, acc = {test_accs:.5f}\")\n",
    "  # 如果模型改进了，在这个时间点保存一个检查点\n",
    "    if test_accs > best_acc:\n",
    "        best_acc = test_accs\n",
    "        net_name=\"skresnet18\"\n",
    "        path=model_path+\"model_weights_2d_\"+f\"{net_name}\"+f'{best_acc}'+\".pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('saving model with acc {:.3f}'.format(best_acc))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21564, 3, 32, 32]) torch.Size([21564])\n",
      "torch.Size([3008, 3, 32, 32]) torch.Size([3008])\n",
      "Finished reading the train set of Leaves Dataset (21564 samples found)\n",
      "Finished reading the valid set of Leaves Dataset (0 samples found)\n",
      "Finished reading the test set of Leaves Dataset (3008 samples found)\n",
      "cpu\n",
      "<bound method Module.parameters of SENet(\n",
      "  (layer0): Sequential(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): SEResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): SEResNetBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): SEResNetBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNetBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): SEResNetBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNetBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (last_linear): Linear(in_features=512, out_features=2, bias=True)\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:42<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个epoch的学习率：0.000100\n",
      "[ Train | 001/050 ] loss = 0.08521, acc = 0.96817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.43355, acc = 0.81516\n",
      "saving model with acc 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:45<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个epoch的学习率：0.000100\n",
      "[ Train | 002/050 ] loss = 0.04605, acc = 0.98251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.48134, acc = 0.80020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:45<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3个epoch的学习率：0.000100\n",
      "[ Train | 003/050 ] loss = 0.03774, acc = 0.98473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.56675, acc = 0.71077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:45<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第4个epoch的学习率：0.000100\n",
      "[ Train | 004/050 ] loss = 0.03224, acc = 0.98891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.34860, acc = 0.78657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:45<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5个epoch的学习率：0.000100\n",
      "[ Train | 005/050 ] loss = 0.02774, acc = 0.98928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 42.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.75746, acc = 0.61968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:46<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第6个epoch的学习率：0.000100\n",
      "[ Train | 006/050 ] loss = 0.02740, acc = 0.98956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.70070, acc = 0.85173\n",
      "saving model with acc 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第7个epoch的学习率：0.000100\n",
      "[ Train | 007/050 ] loss = 0.02151, acc = 0.99151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.73938, acc = 0.47241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:46<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第8个epoch的学习率：0.000100\n",
      "[ Train | 008/050 ] loss = 0.01970, acc = 0.99272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.41085, acc = 0.80519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第9个epoch的学习率：0.000100\n",
      "[ Train | 009/050 ] loss = 0.01835, acc = 0.99313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.16519, acc = 0.78391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第10个epoch的学习率：0.000100\n",
      "[ Train | 010/050 ] loss = 0.02431, acc = 0.99081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.69173, acc = 0.83045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第11个epoch的学习率：0.000100\n",
      "[ Train | 011/050 ] loss = 0.01433, acc = 0.99397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.73325, acc = 0.82547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第12个epoch的学习率：0.000100\n",
      "[ Train | 012/050 ] loss = 0.01089, acc = 0.99550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.59154, acc = 0.82513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第13个epoch的学习率：0.000100\n",
      "[ Train | 013/050 ] loss = 0.01642, acc = 0.99508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.90340, acc = 0.82879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:48<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第14个epoch的学习率：0.000100\n",
      "[ Train | 014/050 ] loss = 0.01956, acc = 0.99411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.86057, acc = 0.83378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:43<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第15个epoch的学习率：0.000100\n",
      "[ Train | 015/050 ] loss = 0.01256, acc = 0.99494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.37375, acc = 0.75532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:46<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第16个epoch的学习率：0.000100\n",
      "[ Train | 016/050 ] loss = 0.01591, acc = 0.99434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.21855, acc = 0.80219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:47<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第17个epoch的学习率：0.000100\n",
      "[ Train | 017/050 ] loss = 0.01147, acc = 0.99550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.60223, acc = 0.66922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:50<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第18个epoch的学习率：0.000100\n",
      "[ Train | 018/050 ] loss = 0.01089, acc = 0.99661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.82982, acc = 0.78624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:50<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第19个epoch的学习率：0.000100\n",
      "[ Train | 019/050 ] loss = 0.00944, acc = 0.99671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.90554, acc = 0.82646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:50<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第20个epoch的学习率：0.000100\n",
      "[ Train | 020/050 ] loss = 0.00733, acc = 0.99791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.05827, acc = 0.71576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:51<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第21个epoch的学习率：0.000100\n",
      "[ Train | 021/050 ] loss = 0.00695, acc = 0.99773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.34839, acc = 0.72839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:51<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第22个epoch的学习率：0.000100\n",
      "[ Train | 022/050 ] loss = 0.00655, acc = 0.99759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.87557, acc = 0.85306\n",
      "saving model with acc 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:50<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第23个epoch的学习率：0.000100\n",
      "[ Train | 023/050 ] loss = 0.00702, acc = 0.99736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.03451, acc = 0.83211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第24个epoch的学习率：0.000100\n",
      "[ Train | 024/050 ] loss = 0.00907, acc = 0.99754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.37406, acc = 0.84076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第25个epoch的学习率：0.000100\n",
      "[ Train | 025/050 ] loss = 0.00521, acc = 0.99828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.30335, acc = 0.81416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第26个epoch的学习率：0.000100\n",
      "[ Train | 026/050 ] loss = 0.00686, acc = 0.99805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.38888, acc = 0.82247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:51<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第27个epoch的学习率：0.000100\n",
      "[ Train | 027/050 ] loss = 0.00432, acc = 0.99824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.65545, acc = 0.80918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:51<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第28个epoch的学习率：0.000100\n",
      "[ Train | 028/050 ] loss = 0.00445, acc = 0.99875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.46434, acc = 0.79023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第29个epoch的学习率：0.000100\n",
      "[ Train | 029/050 ] loss = 0.00673, acc = 0.99773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.83846, acc = 0.66124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第30个epoch的学习率：0.000100\n",
      "[ Train | 030/050 ] loss = 0.00232, acc = 0.99949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.28009, acc = 0.67786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第31个epoch的学习率：0.000100\n",
      "[ Train | 031/050 ] loss = 0.00532, acc = 0.99838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.13574, acc = 0.83045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第32个epoch的学习率：0.000100\n",
      "[ Train | 032/050 ] loss = 0.00339, acc = 0.99903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.11693, acc = 0.80419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第33个epoch的学习率：0.000100\n",
      "[ Train | 033/050 ] loss = 0.00458, acc = 0.99865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.60215, acc = 0.78324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第34个epoch的学习率：0.000100\n",
      "[ Train | 034/050 ] loss = 0.00387, acc = 0.99884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.27174, acc = 0.81915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:52<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第35个epoch的学习率：0.000100\n",
      "[ Train | 035/050 ] loss = 0.00427, acc = 0.99889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.10235, acc = 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第36个epoch的学习率：0.000100\n",
      "[ Train | 036/050 ] loss = 0.00245, acc = 0.99940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.64524, acc = 0.72440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:55<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第37个epoch的学习率：0.000100\n",
      "[ Train | 037/050 ] loss = 0.00464, acc = 0.99870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.05017, acc = 0.80785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第38个epoch的学习率：0.000100\n",
      "[ Train | 038/050 ] loss = 0.00331, acc = 0.99884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.97495, acc = 0.76297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第39个epoch的学习率：0.000100\n",
      "[ Train | 039/050 ] loss = 0.00492, acc = 0.99893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.44674, acc = 0.70146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第40个epoch的学习率：0.000100\n",
      "[ Train | 040/050 ] loss = 0.00187, acc = 0.99940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.70643, acc = 0.66290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第41个epoch的学习率：0.000100\n",
      "[ Train | 041/050 ] loss = 0.00347, acc = 0.99926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.71374, acc = 0.74867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第42个epoch的学习率：0.000100\n",
      "[ Train | 042/050 ] loss = 0.00321, acc = 0.99921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.97100, acc = 0.77759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:54<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第43个epoch的学习率：0.000100\n",
      "[ Train | 043/050 ] loss = 0.00109, acc = 0.99963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.19919, acc = 0.79854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:53<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第44个epoch的学习率：0.000100\n",
      "[ Train | 044/050 ] loss = 0.00428, acc = 0.99879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.51962, acc = 0.77261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:54<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第45个epoch的学习率：0.000100\n",
      "[ Train | 045/050 ] loss = 0.00375, acc = 0.99907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 0.79521, acc = 0.80552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:54<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第46个epoch的学习率：0.000100\n",
      "[ Train | 046/050 ] loss = 0.00341, acc = 0.99893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.44121, acc = 0.77626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:54<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第47个epoch的学习率：0.000100\n",
      "[ Train | 047/050 ] loss = 0.00313, acc = 0.99926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.23469, acc = 0.80452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:55<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第48个epoch的学习率：0.000100\n",
      "[ Train | 048/050 ] loss = 0.00309, acc = 0.99893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 1.41697, acc = 0.81383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:55<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第49个epoch的学习率：0.000100\n",
      "[ Train | 049/050 ] loss = 0.00240, acc = 0.99912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.12883, acc = 0.78923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1347/1347 [05:54<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第50个epoch的学习率：0.000100\n",
      "[ Train | 050/050 ] loss = 0.00142, acc = 0.99958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:04<00:00, 40.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ test ]  loss = 2.75506, acc = 0.72972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm  # timm库有更丰富的预训练模型\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# 设置文件路径并得到数据集\n",
    "train_data_file = \"../CNN/data/train_data/\"\n",
    "test_data_file = \"../CNN/data/test_data/\"\n",
    "# model_path   torch.save(model.state_dict(), '../CNN/Cmodel_weights.pth')\n",
    "model_path = \"../CNN/\"\n",
    "\n",
    "# 超参数\n",
    "learning_rate = 1e-3  # 1e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 16\n",
    "n_epochs = 50\n",
    "best_acc= 0\n",
    "#提取数据\n",
    "def data_image_label(mode):  #shuffle\n",
    "        if mode == 'train':\n",
    "            for i in range(1, 9):\n",
    "                date_path = f\"{train_data_file}\" + \"traindata\" + f\"{i}\" + \".mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            #shuffle\n",
    "            index = [i for i in range(len(data_image))]\n",
    "            random.shuffle(index)\n",
    "            random.shuffle(index)\n",
    "            data_image = data_image[index,:,:,:]\n",
    "            data_label = data_label[index,:]\n",
    "\n",
    "\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            #  #valid_date\n",
    "            # valid_image_tensor=image_tensor[:self.valid_len,:,:,:]\n",
    "            # valid_label_tensor=label_tensor[:self.valid_len]\n",
    "            # #train_date\n",
    "            # image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            # label_tensor=self.label_tensor[self.valid_len:]\n",
    "            # real_len=len(self.image_tensor)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "        elif mode == \"test\":\n",
    "            for i in range(1, 5):\n",
    "                date_path = f\"{test_data_file}\" + \"testdata\" + f\"{i}\" + \"_label.mat\"\n",
    "                if i != 1:\n",
    "                    data_image = np.append(data_image, np.array(h5py.File(date_path)[\"video\"], dtype=np.float32),axis=0)\n",
    "                    data_label = np.append(data_label, np.array(h5py.File(date_path)[\"label\"], dtype=np.float32),axis=0)\n",
    "                else:\n",
    "                    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "                    data_label = np.array(h5py.File(date_path)[\"label\"], dtype=np.float32)\n",
    "            image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "            label_tensor = torch.tensor(data_label.squeeze(), dtype=torch.long)\n",
    "            real_len = len(image_tensor)\n",
    "            print(image_tensor.shape, label_tensor.shape)\n",
    "            return image_tensor,label_tensor,real_len\n",
    "train_image_tensor,train_label_tensor,train_real_len=data_image_label('train')\n",
    "test_image_tensor,test_label_tensor,test_real_len=data_image_label('test')\n",
    "\n",
    "class SAPI_FMF_Dataset(Dataset):\n",
    "    def __init__(self,image_data,label_data,data_len,mode=\"train\", valid_ratio=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (string): 图像文件 路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        self.image_tensor=image_data\n",
    "        self.label_tensor=label_data\n",
    "        self.real_len=data_len\n",
    "        self.mode = mode\n",
    "        self.valid_ratio = valid_ratio\n",
    "        self.valid_len=int(self.valid_ratio*self.real_len)\n",
    "        if self.mode == 'train':\n",
    "            self.image_tensor=self.image_tensor[self.valid_len:,:,:,:]\n",
    "            self.label_tensor=self.label_tensor[self.valid_len:]\n",
    "            self.real_len=len(self.image_tensor)\n",
    "        elif self.mode == 'valid':\n",
    "            self.valid_image_tensor=self.image_tensor[:self.valid_len,:,:,:]\n",
    "            self.valid_label_tensor=self.label_tensor[:self.valid_len]\n",
    "            self.real_len=len(self.valid_image_tensor)\n",
    "        elif self.mode == 'test':\n",
    "            pass\n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.real_len))\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        return self.image_tensor[index, :, :, :], self.label_tensor[index]\n",
    "    def __len__(self):\n",
    "        return self.real_len  # self.real_len = len(self.image_arr) 返回的是训练/验证/测试/图像的数量\n",
    "train_dataset = SAPI_FMF_Dataset(train_image_tensor,train_label_tensor,train_real_len,mode='train')\n",
    "valid_dataset = SAPI_FMF_Dataset( train_image_tensor,train_label_tensor,train_real_len,mode='valid')\n",
    "test_dataset = SAPI_FMF_Dataset( test_image_tensor,test_label_tensor,test_real_len,mode='test')\n",
    "\n",
    "\n",
    "# 定义data loader\n",
    "train_Dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)  # 打开乱序  Falsenum_workers=0)\n",
    "valid_Dataloader = torch.utils.data.DataLoader(dataset=valid_dataset,batch_size=batch_size,shuffle=False,drop_last=True)   #打开乱序  Falsenum_workers=0)\n",
    "test_Dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,drop_last=False)\n",
    "# GPU计算\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "model = timm.create_model(\"legacy_seresnet18\",num_classes=2,in_chans=3,pretrained=True,drop_rate=.5)\n",
    "# model = timm.create_model(\"resnet18\")\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Dropout(.5),\n",
    "#     nn.Linear(model.fc.in_features, 2),\n",
    "#     nn.Dropout(.5)\n",
    "# )\n",
    "model.to(device)\n",
    "model.device = device\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4,\n",
    "                        weight_decay=weight_decay)  # lr=learning_rate,weight_decay= weight_decay\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "print(model.parameters)\n",
    "# train\n",
    "# 对于分类任务，我们使用交叉熵作为性能的度量。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 记录训练信息\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for batch in tqdm(train_Dataloader):\n",
    "        # ---------- Training ----------  以下是训练模型\n",
    "        imgs, labels = batch\n",
    "        # print(imgs.shape)\n",
    "\n",
    "        logits = model(imgs)  # 将图形数据带入模型计算预测\n",
    "        # 计算交叉熵损失\n",
    "        loss = criterion(logits, labels)\n",
    "        # 清除上一步中存储在参数中的梯度。\n",
    "        optimizer.zero_grad()\n",
    "        # 计算参数的梯度。\n",
    "        loss.backward()\n",
    "        # 用计算的梯度更新参数。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算当前批次的精度。   第一维度是0，第二维度是1\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        # 记录损失和准确度\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # 训练集的平均损失和精度是记录值的平均值。\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    # 更新学习率\n",
    "    scheduler.step(train_loss)\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch + 1, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    # 打印信息\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "# ---------- test ----------\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_accs = []\n",
    "    for batch in tqdm(test_Dataloader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # 不需要梯度验证.\n",
    "        # Using  torch.no_grad()  accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # 我们仍然可以计算损失（但不能计算梯度）。\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # 计算当前批次的精度。\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # 记录损失和准确性\n",
    "        test_loss.append(loss.item())\n",
    "        test_accs.append(acc)\n",
    "\n",
    "    # 整个验证集的平均损失和准确度是记录值的平均值\n",
    "    test_loss = sum(test_loss) / len(test_loss)\n",
    "    test_accs = sum(test_accs) / len(test_accs)\n",
    "\n",
    "    # 打印信息.\n",
    "    print(f\"[ test ]  loss = {test_loss:.5f}, acc = {test_accs:.5f}\")\n",
    "  # 如果模型改进了，在这个时间点保存一个检查点\n",
    "    if test_accs > best_acc:\n",
    "        best_acc = test_accs\n",
    "        net_name=\"legacy_seresnet18\"\n",
    "        path=model_path+\"model_weights_2d_\"+f\"{net_name}\"+f'{best_acc}'+\".pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('saving model with acc {:.3f}'.format(best_acc))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([601, 3, 32, 32]) 601\n",
      "Finished reading the  Dataset (601 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 71.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([1000, 3, 32, 32]) 1000\n",
      "Finished reading the  Dataset (1000 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([521, 3, 32, 32]) 521\n",
      "Finished reading the  Dataset (521 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 63.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([621, 3, 32, 32]) 621\n",
      "Finished reading the  Dataset (621 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 68.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_data(i):\n",
    "    date_path = f\"{test_data_file}\" + \"testdata\" + f\"{i}\" + \".mat\"\n",
    "    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "    image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "    real_len = len(image_tensor)\n",
    "    print(image_tensor.shape,real_len)\n",
    "    return image_tensor,real_len\n",
    "\n",
    "class test_result_Dataset(Dataset):\n",
    "    def __init__(self,image_data,data_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (string): 图像文件 路径\n",
    "        \"\"\"\n",
    "        self.image_tensor=image_data\n",
    "        self.real_len=data_len\n",
    "        print('Finished reading the  Dataset ({} samples found)'.format(self.real_len))\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        return self.image_tensor[index, :, :, :]\n",
    "    def __len__(self):\n",
    "        return self.real_len\n",
    "\n",
    "model = timm.create_model(\"resnet10t\",num_classes=2,in_chans=3,pretrained=True,output_stride=8,drop_rate=.5,drop_path_rate=0.5,drop_block_rate=0)\n",
    "# model = timm.create_model(\"resnet18\")\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(.5),\n",
    "    nn.Linear(model.fc.in_features, 2),\n",
    "    nn.Dropout(.5)\n",
    ")\n",
    "model_path=\"../CNN/model_weights_2d__resnet10_0.8354388475418091.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "for i in range(5,9):\n",
    "    test_data5_image,test_data5_len=test_data(i)\n",
    "    test_dataset5 = test_result_Dataset(test_data5_image,test_data5_len)\n",
    "    test_Dataloader5 = torch.utils.data.DataLoader(dataset=test_dataset5, batch_size=batch_size, shuffle=False,drop_last=False)\n",
    "    predictions = []\n",
    "    for batch in tqdm(test_Dataloader5):\n",
    "        imgs = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "        predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "    print(predictions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([601, 3, 32, 32]) 601\n",
      "Finished reading the  Dataset (601 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 65.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([1000, 3, 32, 32]) 1000\n",
      "Finished reading the  Dataset (1000 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 74.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([521, 3, 32, 32]) 521\n",
      "Finished reading the  Dataset (521 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 70.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "torch.Size([621, 3, 32, 32]) 621\n",
      "Finished reading the  Dataset (621 samples found)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 62.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def test_data(i):\n",
    "    date_path = f\"{test_data_file}\" + \"testdata\" + f\"{i}\" + \".mat\"\n",
    "    data_image = np.array(h5py.File(date_path)[\"video\"], dtype=np.float32)\n",
    "    image_tensor = torch.tensor(data_image, dtype=torch.float32)\n",
    "    real_len = len(image_tensor)\n",
    "    print(image_tensor.shape,real_len)\n",
    "    return image_tensor,real_len\n",
    "\n",
    "class test_result_Dataset(Dataset):\n",
    "    def __init__(self,image_data,data_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (string): 图像文件 路径\n",
    "        \"\"\"\n",
    "        self.image_tensor=image_data\n",
    "        self.real_len=data_len\n",
    "        print('Finished reading the  Dataset ({} samples found)'.format(self.real_len))\n",
    "    def __getitem__(self, index):\n",
    "        # 从 image_arr中得到索引对应的文件名\n",
    "        return self.image_tensor[index, :, :, :]\n",
    "    def __len__(self):\n",
    "        return self.real_len\n",
    "\n",
    "model = timm.create_model(\"resnet10t\",num_classes=2,in_chans=3,pretrained=True,output_stride=8,drop_rate=.5,drop_path_rate=0.5,drop_block_rate=0)\n",
    "# model = timm.create_model(\"resnet18\")\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(.5),\n",
    "    nn.Linear(model.fc.in_features, 2),\n",
    "    nn.Dropout(.5)\n",
    ")\n",
    "model_path=\"../CNN/model_weights_2d__resnet10_0.8447473645210266.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "for i in range(5,9):\n",
    "    test_data_image,test_data_len=test_data(i)\n",
    "    test_dataset = test_result_Dataset(test_data_image,test_data_len)\n",
    "    test_Dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,drop_last=False)\n",
    "    predictions = []\n",
    "    for batch in tqdm(test_Dataloader):\n",
    "        imgs = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "        predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "    excel_path=\"../CNN/data/test_data/testdata\"+f\"{i}\"+\"_cls.xlsx\"\n",
    "    index=np.array(range(1,test_data_len+1)).tolist()\n",
    "    data_toexcel={\"index\":index,\"result\":predictions}\n",
    "    data_toexcel = pd.DataFrame(data_toexcel)\n",
    "    data_toexcel.to_excel(excel_path, sheet_name=\"sheet1\",index=False)\n",
    "    print(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
